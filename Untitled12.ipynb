{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKgAH6jB35oox5SHVGEGKL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksaishivani/Heart-disease/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZmyJM3FOm6Q",
        "outputId": "2b72f2ff-1888-4d28-d0a4-12f8bad7f17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from Kaggle...\n",
            "\n",
            "Dataset Preview:\n",
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
            "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
            "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
            "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
            "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
            "\n",
            "   ca  thal  target  \n",
            "0   2     3       0  \n",
            "1   0     3       0  \n",
            "2   0     3       0  \n",
            "3   1     3       0  \n",
            "4   3     2       0  \n",
            "\n",
            "Logistic Regression Accuracy: 0.7951\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.72      0.78       102\n",
            "           1       0.76      0.87      0.81       103\n",
            "\n",
            "    accuracy                           0.80       205\n",
            "   macro avg       0.80      0.79      0.79       205\n",
            "weighted avg       0.80      0.80      0.79       205\n",
            "\n",
            "Confusion Matrix:\n",
            "[[73 29]\n",
            " [13 90]]\n",
            "\n",
            "Decision Tree Accuracy: 0.9854\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       102\n",
            "           1       1.00      0.97      0.99       103\n",
            "\n",
            "    accuracy                           0.99       205\n",
            "   macro avg       0.99      0.99      0.99       205\n",
            "weighted avg       0.99      0.99      0.99       205\n",
            "\n",
            "Confusion Matrix:\n",
            "[[102   0]\n",
            " [  3 100]]\n",
            "\n",
            "Random Forest Accuracy: 0.9854\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       102\n",
            "           1       1.00      0.97      0.99       103\n",
            "\n",
            "    accuracy                           0.99       205\n",
            "   macro avg       0.99      0.99      0.99       205\n",
            "weighted avg       0.99      0.99      0.99       205\n",
            "\n",
            "Confusion Matrix:\n",
            "[[102   0]\n",
            " [  3 100]]\n",
            "\n",
            "SVM Accuracy: 0.8878\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.83      0.88       102\n",
            "           1       0.85      0.94      0.89       103\n",
            "\n",
            "    accuracy                           0.89       205\n",
            "   macro avg       0.89      0.89      0.89       205\n",
            "weighted avg       0.89      0.89      0.89       205\n",
            "\n",
            "Confusion Matrix:\n",
            "[[85 17]\n",
            " [ 6 97]]\n",
            "\n",
            "Best Model: Decision Tree with Accuracy 0.9854\n",
            "Model and scaler saved as best_model.pkl and scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "heart_disease_ml.py\n",
        "Complete ML pipeline for UCI Heart Disease dataset (Cleveland subset).\n",
        "Trains multiple models, compares performance, saves best model and scaler.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import joblib\n",
        "import kagglehub\n",
        "\n",
        "# 1. Download dataset from Kaggle\n",
        "print(\"Downloading dataset from Kaggle...\")\n",
        "dataset_path = kagglehub.dataset_download(\"johnsmith88/heart-disease-dataset\")\n",
        "csv_path = os.path.join(dataset_path, \"heart.csv\")\n",
        "\n",
        "if not os.path.exists(csv_path):\n",
        "    raise FileNotFoundError(f\"Dataset not found in {csv_path}\")\n",
        "\n",
        "# 2. Load dataset\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"\\nDataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# 3. Prepare data\n",
        "X = df.drop(\"target\", axis=1)\n",
        "y = df[\"target\"]\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 4. Train models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[name] = acc\n",
        "    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 5. Save best model\n",
        "best_model_name = max(results, key=results.get)\n",
        "best_model = models[best_model_name]\n",
        "joblib.dump(best_model, \"best_model.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name} with Accuracy {results[best_model_name]:.4f}\")\n",
        "print(\"Model and scaler saved as best_model.pkl and scaler.pkl\")"
      ]
    }
  ]
}